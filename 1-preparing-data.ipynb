{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import make_data\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Folder to store all the data\n",
    "DATA_FOLDER = Path(\"/path/to/data/folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Download AlphaFold (AF) database proteins as tar files and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "make_data.download_data(DATA_FOLDER)\n",
    "make_data.extract_data(DATA_FOLDER, DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Download UniProt annotations for all AF proteins, split by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uniprot_folder = DATA_FOLDER / \"uniprot_files\"\n",
    "if not uniprot_folder.exists():\n",
    "    uniprot_folder.mkdir()\n",
    "make_data.get_uniprot_info(DATA_FOLDER, uniprot_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get average pLDDT scores, number of high confidence residues, and total number of residues for each AF protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3988it [01:33, 42.74it/s]\n",
      "19694it [10:20, 31.73it/s]\n",
      "12622it [09:22, 22.44it/s]\n",
      "23391it [21:38, 18.01it/s]\n",
      "27434it [16:18, 28.05it/s]\n",
      "39299it [22:24, 29.22it/s]\n",
      "4363it [02:29, 29.27it/s]\n",
      "13458it [09:59, 22.45it/s]\n",
      "1773it [00:51, 34.39it/s]\n",
      "5187it [05:02, 17.14it/s]\n",
      "19036it [13:44, 23.09it/s]\n",
      "6040it [04:20, 23.15it/s]\n",
      "5128it [03:46, 22.66it/s]\n",
      "21272it [16:47, 21.10it/s]\n",
      "7924it [07:17, 18.10it/s]\n",
      "2888it [01:25, 33.86it/s]\n",
      "55799it [32:34, 28.55it/s]\n",
      "5974it [04:12, 23.64it/s]]\n",
      "21615it [15:28, 23.29it/s]\n"
     ]
    }
   ],
   "source": [
    "avg_scores, lengths_high_confidence, lengths_full = make_data.get_AF_protein_information(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_folder = DATA_FOLDER / \"uniprot_go\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Combine all UniProt data and scores into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/backup2/geometric/geo_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pnd\n",
    "AF_dataframe = pnd.concat([pnd.read_csv(filename, sep=\"\\t\") for filename in uniprot_folder.glob(\"UP*_uniprot.txt\")])\n",
    "AF_dataframe[\"Protein family\"] = [str(val).split(\",\")[0] for val in AF_dataframe[\"Protein families\"]] # Superfamily\n",
    "AF_dataframe[\"Organism\"] = [\" \".join(str(val).split(\" (\")[0].split(\" \")[:2]) for val in AF_dataframe[\"Organism\"]]\n",
    "AF_dataframe[\"ID\"] = [f\"AF-{k}-F1-model_v1.pdb\" for k in AF_dataframe[\"Entry\"]]\n",
    "AF_dataframe[\"Avg. score\"] = [avg_scores[key] if key in avg_scores else 40 for key in AF_dataframe[\"ID\"]]\n",
    "AF_dataframe[\"Length\"] = [lengths_full[key] if key in lengths_full else 0 for key in AF_dataframe[\"ID\"]]\n",
    "AF_dataframe[\"High confidence length\"] = [lengths_high_confidence[key] if key in lengths_high_confidence else 0 for key in AF_dataframe[\"ID\"]]\n",
    "\n",
    "AF_dataframe = AF_dataframe[[c for c in AF_dataframe.columns if not c.startswith(\"yourlist\")]]\n",
    "AF_dataframe.to_csv(DATA_FOLDER / \"AF_dataframe.txt\", sep=\"\\t\")\n",
    "AF_dataframe = AF_dataframe.set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Calculate shapemers for each AF protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "make_data.get_AF_shapemers(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Download and extract CASP12 data from\n",
    "`https://sharehost.hms.harvard.edu/sysbio/alquraishi/proteinnet/human_readable/casp12.tar.gz`\n",
    "into DATA_FOLDER / casp12\n",
    "\n",
    "Calculate shapemers for all CASP12 proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "make_data.get_PDB_shapemers(DATA_FOLDER / \"casp12\" / \"training_100\",\n",
    "                            DATA_FOLDER)\n",
    "make_data.get_PDB_shapemers(DATA_FOLDER / \"casp12\" / \"validation\",\n",
    "                            DATA_FOLDER)\n",
    "make_data.get_PDB_shapemers(DATA_FOLDER / \"casp12\" / \"testing\",\n",
    "                            DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get UniProt annotations for all PDB proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1043it [16:36,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from src import uniprot_parser\n",
    "import pickle\n",
    "\n",
    "corpus_files = DATA_FOLDER.glob(\"*_ids_corpus_res4_6*.txt\")\n",
    "keys = (line.strip().split(\"\\t\")[0] for line in itertools.chain.from_iterable((open(file) for file in corpus_files)))\n",
    "pdb_ids = []\n",
    "for k in keys:\n",
    "    if k.endswith(\".pdb\"):\n",
    "        continue\n",
    "    if \"#\" in k:\n",
    "        if \"TBM\" in k or \"FM\" in k:\n",
    "            continue\n",
    "        k = k.split(\"#\")[1][:4]\n",
    "    else:\n",
    "        k = k[:4]\n",
    "    pdb_ids.append(k)\n",
    "uniprot_parser.get_uniprot_info_from_ids(pdb_ids,\n",
    "                                         DATA_FOLDER / \"uniprot_go\" / \"casp12_uniprot.txt\",\n",
    "                                         identifier=\"PDB_ID\",\n",
    "                                         columns=make_data.UNIPROT_COLUMNS,\n",
    "                                         chunk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "coords = make_data.get_PDB_protein_information([DATA_FOLDER / \"casp12\" / f for f in [\"training_100\",\n",
    "                                                                                     \"validation\",\n",
    "                                                                                     \"testing\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(DATA_FOLDER / \"PDB_coords.pkl\", \"wb\") as f:\n",
    "    pickle.dump(coords, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PDB_dataframe = pnd.read_csv(DATA_FOLDER / \"uniprot_go\" / \"casp12_uniprot.txt\", sep=\"\\t\")\n",
    "mapping_column = [c for c in PDB_dataframe.columns if c.startswith(\"yourlist\")][0]\n",
    "PDB_dataframe[\"PDB_ID\"] = PDB_dataframe[mapping_column]\n",
    "PDB_dataframe[\"Protein family\"] = [str(val).split(\",\")[0] for val in PDB_dataframe[\"Protein families\"]] # Superfamily\n",
    "PDB_dataframe[\"Organism\"] = [\" \".join(str(val).split(\" (\")[0].split(\" \")[:2]) for val in PDB_dataframe[\"Organism\"]]\n",
    "PDB_dataframe = PDB_dataframe[[c for c in PDB_dataframe.columns if c != mapping_column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Match AF proteins with previously determined PDB proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "AF_PDB_cross_references = AF_dataframe['Cross-reference (PDB)'][AF_dataframe['Cross-reference (PDB)'].notna()]\n",
    "AF_PDB_mapping = {key: AF_PDB_cross_references[key] for key in AF_PDB_cross_references.keys()}\n",
    "PDB_AF_mapping = defaultdict(list)\n",
    "for p in AF_PDB_mapping:\n",
    "    if type(AF_PDB_mapping[p]) == str:\n",
    "        for p1 in AF_PDB_mapping[p][:-1].split(\";\"):\n",
    "            PDB_AF_mapping[p1].append(p)\n",
    "    else:\n",
    "        for p1 in AF_PDB_mapping[p].values:\n",
    "            PDB_AF_mapping[p1[:-1]].append(p)\n",
    "\n",
    "PDB_dataframe[\"AF\"] = [\";\".join(PDB_AF_mapping[p]) if p in PDB_AF_mapping else np.nan for p in PDB_dataframe[\"PDB_ID\"]]\n",
    "PDB_dataframe.to_csv(DATA_FOLDER / \"PDB_dataframe.txt\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
